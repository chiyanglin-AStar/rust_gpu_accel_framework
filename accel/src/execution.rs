use crate::{contexted_call, device::*, error::*, *};
use cuda::*;
use std::{ffi::*, ptr::null_mut};

/// Type which can be sent to the device as kernel argument
///
/// ```
/// # use accel::*;
/// # use std::ffi::*;
/// let a: i32 = 10;
/// let p = &a as *const i32;
/// assert_eq!(
///     DeviceSend::as_ptr(&p),
///     &p as *const *const i32 as *mut c_void
/// );
/// assert!(std::ptr::eq(
///     unsafe { *(DeviceSend::as_ptr(&p) as *mut *const i32) },
///     p
/// ));
/// ```
pub trait DeviceSend: Sized {
    /// Get the address of this value
    fn as_ptr(&self) -> *mut c_void {
        self as *const Self as *mut c_void
    }
}

// Use default impl
impl<T> DeviceSend for *mut T {}
impl<T> DeviceSend for *const T {}
impl DeviceSend for bool {}
impl DeviceSend for i8 {}
impl DeviceSend for i16 {}
impl DeviceSend for i32 {}
impl DeviceSend for i64 {}
impl DeviceSend for isize {}
impl DeviceSend for u8 {}
impl DeviceSend for u16 {}
impl DeviceSend for u32 {}
impl DeviceSend for u64 {}
impl DeviceSend for usize {}
impl DeviceSend for f32 {}
impl DeviceSend for f64 {}

pub trait ArgRef {
    fn as_ptr(&self) -> *mut *mut c_void {
        self as *const Self as *mut *mut c_void
    }
}

// Generate `ArgRef*` structs like
//
// ```
// #[repr(C)]
// pub struct ArgRef2<'arg, D1: DeviceSend, D2: DeviceSend> {
//     pub arg1: &'arg D1,
//     pub arg2: &'arg D2,
// }
// ```
//
// and impls for `Send`, `Sync`, `From(&D1, &D2)`, and `ArgRef`
accel_derive::define_argref!(12 /* 1..=4 */);

/// Typed CUDA Kernel launcher
///
/// This will be automatically implemented in [accel_derive::kernel] for autogenerated wrapper
/// module of [Module].
///
/// ```
/// #[accel_derive::kernel]
/// fn f(a: i32) {}
/// ```
///
/// will create a submodule `f`:
///
/// ```
/// mod f {
///     pub const PTX_STR: &str = "PTX string generated by rustc/nvptx64-nvidia-cuda";
///     pub struct Module(::accel::Module);
///     /* impl Module { ... } */
///     /* impl Launchable for Module { ... } */
/// }
/// ```
///
/// Implementation of `Launchable` for `f::Module` is also generated by [accel_derive::kernel]
/// proc-macro.
///
/// [accel_derive::kernel]: https://docs.rs/accel-derive/0.3.0-alpha.1/accel_derive/attr.kernel.html
/// [Module]: struct.Module.html
pub trait Launchable<'arg> {
    /// Arguments for the kernel to be launched.
    /// This must be a tuple of [DeviceSend] types.
    ///
    /// [DeviceSend]: trait.DeviceSend.html
    type Args: ArgRef;

    fn get_kernel(&self) -> Result<Kernel>;

    /// Launch CUDA Kernel synchronously
    ///
    /// ```
    /// use accel::*;
    ///
    /// #[accel_derive::kernel]
    /// fn f(a: i32) {}
    ///
    /// let device = Device::nth(0)?;
    /// let ctx = device.create_context();
    /// let module = f::Module::new(&ctx)?;
    /// let a = 12;
    /// module.launch((1,) /* grid */, (4,) /* block */, (&a,))?; // wait until kernel execution ends
    /// # Ok::<(), ::accel::error::AccelError>(())
    /// ```
    fn launch<G: Into<Grid>, B: Into<Block>>(
        &self,
        grid: G,
        block: B,
        args: impl Into<Self::Args>,
    ) -> Result<()> {
        let grid = grid.into();
        let block = block.into();
        let kernel = self.get_kernel()?;
        let args: Self::Args = args.into();
        unsafe {
            contexted_call!(
                &kernel,
                cuLaunchKernel,
                kernel.func,
                grid.x,
                grid.y,
                grid.z,
                block.x,
                block.y,
                block.z,
                0,          /* FIXME: no shared memory */
                null_mut(), /* use default stream */
                args.as_ptr(),
                null_mut() /* no extra */
            )?;
        }
        kernel.sync()?;
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn arg_ref2() {
        let a: i32 = 10;
        let b: f32 = 1.0;
        let args: ArgRef2<'_, i32, f32> = (&a, &b).into();
        let args_ptrs: &[*mut c_void] = unsafe { std::slice::from_raw_parts(args.as_ptr(), 2) };
        assert_eq!(
            args_ptrs,
            &[&a as *const _ as *mut c_void, &b as *const _ as *mut c_void]
        );
    }
}
